# Literature Review

Over the past several years, researchers have been exploring intelligent multi-agent systems to automate data analysis and report generation. These studies provide the foundation for designing our AI-Driven Automated Report Generation System, helping us combine data interpretation, visualization, and narrative reporting into a coherent pipeline.

**Wenyi Xu, Yuren Mao, Xiaolu Zhang, Chao Zhang, Xuemei Dong, Mengfei Zhang, Jun Zhou, and Yunjun Gao (2025)** present *“DAgent: A Relational Database-Driven Data Analysis Report Generation Agent”*. DAgent is a multi-agent system that produces analytical reports from relational databases. It’s organized into three parts: a **Planner**, which breaks down analytical goals into smaller tasks; a **Tool**, which performs operations like SQL queries and visualizations; and a **Memory**, which keeps track of context for multi-step reasoning. This clear separation of planning, execution, and memory gave us a strong blueprint for designing our own Supervisor, Assistant, and Metadata Agents, allowing our system to analyze datasets step by step while maintaining coherence.

**Bingxuan Li, Yiwei Wang, Jiuxiang Gu, Kai-Wei Chang, and Nanyun Peng (2025)** introduce *“METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling”*. METAL focuses on creating high-quality visualizations through an iterative multi-agent process: some agents generate charts, others critique visuals, review code, and make revisions. This idea inspired our Assistant Agent’s feedback loop, helping our system produce robust visualizations that get refined before reaching the final report.

**Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, Börje F. Karlsson, Jie Fu, and Yemin Shi (2024)** present *“AutoAgents: A Framework for Automatic Agent Generation”*, which highlights the benefits of dynamically creating and coordinating specialized agents. AutoAgents assesses the task at hand and assembles an appropriate team of agents, with a supervising observer monitoring the process. This influenced how we built our Supervisor Agent, giving it the flexibility to delegate tasks to specialized sub-agents based on dataset characteristics and analytical goals.

**Liu et al. (2023)** explore *“Data2Text Agents: Tabular Data Summarization with LLMs”*, showing how structured data can be turned into readable natural-language summaries using large language models. They combine statistical reasoning with text generation to explain patterns in the data. Our Metadata Agent draws on the same concept, transforming schema information, column distributions, and relationships into narrative summaries that provide context for the downstream agents.

**Kevin Z. Hu, Michiel A. Bakker, Stephen Li, Tim Kraska, and César Hidalgo (2019)** developed *“VizML: A Machine Learning Approach to Visualization Recommendation”*. VizML predicts suitable chart types based on dataset features using patterns learned from a large collection of dataset-visualization pairs. This concept helped shape our Assistant Agent’s approach to selecting visualizations, enabling it to suggest charts like histograms, scatter plots, or heatmaps based on the dataset’s characteristics.

The work of **Nguyen et al. (2021, AutoReport)** and **Roberts et al. (2020, Table2Text)** also contributes valuable lessons. AutoReport focuses on automatically extracting KPIs and generating structured reports, guiding our Report Generation Layer. Table2Text demonstrates how tables can be converted into clear, fluent text summaries, which influenced how the Metadata Agent explains column relationships and distributions.

In addition to academic research, open-source tools provide practical support. The **AutoAgents GitHub repository (Link-AGI/AutoAgents)** offers a multi-agent framework that supports dynamic agent creation, communication between agents, and tool integration. Using such infrastructure lets us focus on our system’s unique tasks — metadata profiling, analysis, and report generation — without worrying about low-level agent management. Community-driven frameworks like **Atomic Agents** provide reusable pipelines and sandboxed execution, further supporting scalable and maintainable multi-agent systems.

Together, these studies and tools highlight the importance of **specialized agents, modular task decomposition, iterative feedback loops, dynamic coordination, and semantic grounding**. Our project builds on these concepts and extends them to handle **multi-format datasets (CSV, Parquet, API)**, creating an **end-to-end pipeline** that turns pre-cleaned and profiled data into fully generated, interpretable reports.
